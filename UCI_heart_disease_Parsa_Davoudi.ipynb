{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "tTSZWv7Kvl07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2vh7apUghUE",
        "outputId": "3611faef-5018-40a5-918b-c8332a43f93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-46c66418-acf1-435a-b00b-f6cfb63c27b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-46c66418-acf1-435a-b00b-f6cfb63c27b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart_disease_uci.xlsx to heart_disease_uci.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming one file is uploaded\n",
        "for fn in uploaded.keys():\n",
        "    df = pd.read_excel(fn)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "***this section has 6 steps***"
      ],
      "metadata": {
        "id": "rHvrW7q2gipH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA.01**"
      ],
      "metadata": {
        "id": "9OjTNpY9hpPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Shape\n",
        "print(\"🔹 Dataset Shape:\")\n",
        "print(f\"Rows: {df.shape[0]}, columns: {df.shape[1]}\\n\")\n",
        "\n",
        "# 2. Column Names and Data Types\n",
        "print(\"🔹 Column Names and Data Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Missing Values\n",
        "print(\"🔹 Missing Values per Column:\")\n",
        "missing = df.isnull().sum()\n",
        "missing = missing[missing > 0]\n",
        "if not missing.empty:\n",
        "    print(missing)\n",
        "else:\n",
        "    print(\"No missing values found.\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# 4. Basic Statistics\n",
        "print(\"🔹 Summary Statistics for Numerical Features:\")\n",
        "print(df.describe().T[['mean', 'std', 'min', 'max']])"
      ],
      "metadata": {
        "id": "VvqCEq4MvOxx",
        "outputId": "f6fc2c56-fd06-45bf-dfa0-2430dc841c95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Dataset Shape:\n",
            "Rows: 920, columns: 16\n",
            "\n",
            "🔹 Column Names and Data Types:\n",
            "id            int64\n",
            "age           int64\n",
            "sex          object\n",
            "dataset      object\n",
            "cp           object\n",
            "trestbps    float64\n",
            "chol        float64\n",
            "fbs         float64\n",
            "restecg      object\n",
            "thalch      float64\n",
            "exang       float64\n",
            "oldpeak     float64\n",
            "slope        object\n",
            "ca          float64\n",
            "thal         object\n",
            "num           int64\n",
            "dtype: object\n",
            "\n",
            "\n",
            "🔹 Missing Values per Column:\n",
            "trestbps     59\n",
            "chol         30\n",
            "fbs          90\n",
            "restecg       2\n",
            "thalch       55\n",
            "exang        55\n",
            "oldpeak      62\n",
            "slope       309\n",
            "ca          611\n",
            "thal        486\n",
            "dtype: int64\n",
            "\n",
            "\n",
            "🔹 Summary Statistics for Numerical Features:\n",
            "                mean         std   min    max\n",
            "id        460.500000  265.725422   1.0  920.0\n",
            "age        53.510870    9.424685  28.0   77.0\n",
            "trestbps  132.132404   19.066070   0.0  200.0\n",
            "chol      199.130337  110.780810   0.0  603.0\n",
            "fbs         0.166265    0.372543   0.0    1.0\n",
            "thalch    137.545665   25.926276  60.0  202.0\n",
            "exang       0.389595    0.487941   0.0    1.0\n",
            "oldpeak     0.878788    1.091226  -2.6    6.2\n",
            "ca          0.676375    0.935653   0.0    3.0\n",
            "num         0.995652    1.142693   0.0    4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA.02**"
      ],
      "metadata": {
        "id": "Jvo-VehR3fpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Target variable\n",
        "target = 'num'\n",
        "\n",
        "# Value counts\n",
        "print(\"🔹 Target Value Counts:\")\n",
        "print(df[target].value_counts())\n",
        "\n",
        "# Relative frequency\n",
        "print(\"\\n🔹 Target Class Proportions:\")\n",
        "print(df[target].value_counts(normalize=True))\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=df, x=target, palette='coolwarm')\n",
        "plt.title(\"Distribution of Target Variable: Heart Disease Severity\")\n",
        "plt.xlabel(\"Heart Disease Class (num)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8XuB0Hk_3mLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA.03**"
      ],
      "metadata": {
        "id": "mAhzJ8QICuXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Identify Feature Types ####################\n",
        "\n",
        "# Drop target column\n",
        "features = df.drop(columns=['num'])\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "numerical_cols = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = features.select_dtypes(include='object').columns\n",
        "\n",
        "print(\"🔹 Numerical Features:\", list(numerical_cols))\n",
        "print(\"🔹 Categorical Features:\", list(categorical_cols))\n",
        "\n",
        "\n",
        "# Plot Numerical Features ####################\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Histograms\n",
        "features[numerical_cols].hist(figsize=(15, 10), bins=20, color='skyblue', edgecolor='black')\n",
        "plt.suptitle(\"Histograms of Numerical Features\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplots\n",
        "plt.figure(figsize=(15, 8))\n",
        "for i, col in enumerate(numerical_cols, 1):\n",
        "    plt.subplot(3, 5, i)\n",
        "    sns.boxplot(y=features[col], color='lightgreen')\n",
        "    plt.title(col)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Plot Categorical Features ####################\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n🔹 Frequency Table for {col}\")\n",
        "    print(features[col].value_counts())\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.countplot(data=features, x=col, palette='pastel')\n",
        "    plt.title(f\"Bar Plot of {col}\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "0ITmrGnWC4lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA.04**"
      ],
      "metadata": {
        "id": "igR3dN0KIuZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify Feature Types ####################\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('num')\n",
        "categorical_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "\n",
        "# Numerical vs Target – Boxplots & T-tests ####################\n",
        "from scipy.stats import ttest_ind\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.boxplot(data=df, x='num', y=col, palette='coolwarm')\n",
        "    plt.title(f\"{col} vs num\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    group0 = df[df['num'] == 0][col]\n",
        "    group1 = df[df['num'] != 0][col]\n",
        "    t_stat, p_val = ttest_ind(group0, group1, nan_policy='omit')\n",
        "    print(f\"T-test for {col}: t-stat = {t_stat:.2f}, p-value = {p_val:.4f}\")\n",
        "\n",
        "    # Categorical vs Target – Stacked Bar Plots ####################\n",
        "    for col in categorical_cols:\n",
        "      ct = pd.crosstab(df[col], df['num'], normalize='index')\n",
        "      ct.plot(kind='bar', stacked=True, figsize=(6, 4), colormap='Set2')\n",
        "    plt.title(f\"{col} vs num\")\n",
        "    plt.ylabel(\"Proportion\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OkiHChVfIu4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA.05"
      ],
      "metadata": {
        "id": "CN5w-y2RJLI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Matrix ####################\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Select numerical columns including target\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr = df[numerical_cols].corr()\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title(\"Correlation Matrix of Numerical Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Pairplot (Optional but Insightful) ####################\n",
        "selected = numerical_cols[:5].tolist() + ['num']  # Pick top 5 for clarity\n",
        "sns.pairplot(df[selected], hue='num', palette='husl')\n",
        "plt.suptitle(\"Pairplot of Selected Features\", y=1.02)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MivK45xRJJ84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA.06**"
      ],
      "metadata": {
        "id": "lNr_pR6eJvJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skewness of Numerical Features ####################\n",
        "from scipy.stats import skew\n",
        "\n",
        "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('num')\n",
        "\n",
        "print(\"🔹 Skewness of Numerical Features:\")\n",
        "for col in numerical_cols:\n",
        "    sk = skew(df[col].dropna())\n",
        "    print(f\"{col}: skewness = {sk:.2f}\")\n",
        "\n",
        "\n",
        "# Outlier Detection Using IQR ####################\n",
        "print(\"\\n🔹 Outlier Counts (IQR Method):\")\n",
        "for col in numerical_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    outliers = df[(df[col] < Q1 - 1.5 * IQR) | (df[col] > Q3 + 1.5 * IQR)]\n",
        "    print(f\"{col}: {len(outliers)} outliers\")\n",
        "\n",
        "\n",
        "# Spot Invalid Values ####################\n",
        "print(\"\\n🔹 Invalid Value Checks:\")\n",
        "print(\"Negative values in 'chol':\", (df['chol'] < 0).sum())\n",
        "print(\"Negative values in 'trestbps':\", (df['trestbps'] < 0).sum())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NFvheFLdJziu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "_tAJovcljYxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 1. Load dataset\n",
        "df = pd.read_excel(\"heart_disease_uci.xlsx\")\n",
        "print(\"Columns:\", df.columns)\n",
        "\n",
        "# 2. Transform target into binary classification (0 = no disease, 1 = disease)\n",
        "df[\"target\"] = (df[\"num\"] > 0).astype(int)\n",
        "df = df.drop(columns=[\"num\"])  # drop original target\n",
        "\n",
        "# 3. Identify numerical and categorical columns\n",
        "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.drop(\"target\")\n",
        "categorical_cols = df.select_dtypes(include=\"object\").columns\n",
        "\n",
        "# 4. Define preprocessing pipelines\n",
        "num_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformer, numeric_cols),\n",
        "        (\"cat\", cat_transformer, categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 5. Define models to compare\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# 6. Split dataset (stratified to preserve class balance)\n",
        "X = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 7. Cross-validation for model comparison\n",
        "cv_results = {}\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", model)\n",
        "    ])\n",
        "    scores = cross_validate(\n",
        "        pipeline, X_train, y_train, cv=skf,\n",
        "        scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
        "    )\n",
        "    cv_results[name] = {metric: np.mean(scores[f\"test_{metric}\"]) for metric in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]}\n",
        "\n",
        "results_df = pd.DataFrame(cv_results).T.sort_values(by=\"roc_auc\", ascending=False)\n",
        "print(\"\\n📊 Cross-validation results (mean scores across folds):\")\n",
        "print(results_df.round(3))\n",
        "\n",
        "# 8. Test set evaluation for each model\n",
        "test_results = {}\n",
        "roc_fig, roc_ax = plt.subplots(figsize=(7, 6))\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", model)\n",
        "    ])\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Store test metrics\n",
        "    test_results[name] = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred),\n",
        "        \"recall\": recall_score(y_test, y_pred),\n",
        "        \"f1\": f1_score(y_test, y_pred),\n",
        "        \"roc_auc\": auc(*roc_curve(y_test, y_proba)[:2])\n",
        "    }\n",
        "\n",
        "    # Print classification report\n",
        "    print(f\"\\n🔎 Classification Report for {name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    ConfusionMatrixDisplay(cm).plot(cmap=\"Blues\")\n",
        "    plt.title(f\"Confusion Matrix - {name}\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC curve\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    roc_ax.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.2f})\")\n",
        "\n",
        "# Final ROC curve plot for all models\n",
        "roc_ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"grey\")\n",
        "roc_ax.set_xlabel(\"False Positive Rate\")\n",
        "roc_ax.set_ylabel(\"True Positive Rate\")\n",
        "roc_ax.set_title(\"ROC Curves for All Models\")\n",
        "roc_ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# 9. Summary table of test-set metrics\n",
        "test_results_df = pd.DataFrame(test_results).T.sort_values(by=\"roc_auc\", ascending=False)\n",
        "print(\"\\n📊 Test set evaluation results:\")\n",
        "print(test_results_df.round(3))\n",
        "\n",
        "# 10. Identify and recommend best model\n",
        "best_model = test_results_df.iloc[0]\n",
        "best_name = test_results_df.index[0]\n",
        "print(\"\\n✅ Best model:\", best_name)\n",
        "print(best_model.round(3))\n",
        "print(f\"\\n👉 Recommendation: {best_name} performed the best with ROC-AUC = {best_model['roc_auc']:.3f}, making it the most suitable model for this dataset.\")\n"
      ],
      "metadata": {
        "id": "lt748pFBjf-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}